{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fa872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType, TimestampType, DoubleType, LongType\n",
    "from pyspark.sql.functions import col, from_unixtime, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8739b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = '/home/xiangivyli/.gc/google_credential_spark.json'\n",
    "\n",
    "# First, stop the existing Spark session if it's running\n",
    "if 'spark' in locals():\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('RepartitionApp') \\\n",
    "    .set(\"spark.jars\", \"/home/xiangivyli/lib/gcs-connector-hadoop3-2.2.5.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2030d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/30 10:08:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/30 10:08:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/03/30 10:08:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813ee360",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36127cc0",
   "metadata": {},
   "source": [
    "## Read parquet files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74fced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Spark schema\n",
    "job_postings_schema = StructType([\n",
    "    StructField(\"job_id\", StringType(), True),\n",
    "    StructField(\"company_id\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"max_salary\", FloatType(), True),\n",
    "    StructField(\"med_salary\", FloatType(), True),\n",
    "    StructField(\"min_salary\", FloatType(), True),\n",
    "    StructField(\"pay_period\", StringType(), True),\n",
    "    StructField(\"formatted_work_type\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"applies\", IntegerType(), True),\n",
    "    StructField(\"original_listed_time\", LongType(), True),\n",
    "    StructField(\"remote_allowed\", StringType(), True),\n",
    "    StructField(\"views\", IntegerType(), True),\n",
    "    StructField(\"job_posting_url\", StringType(), True),\n",
    "    StructField(\"application_url\", StringType(), True),\n",
    "    StructField(\"application_type\", StringType(), True),\n",
    "    StructField(\"expiry\", LongType(), True),\n",
    "    StructField(\"closed_time\", LongType(), True),\n",
    "    StructField(\"formatted_experience_level\", StringType(), True),\n",
    "    StructField(\"skills_desc\", StringType(), True),\n",
    "    StructField(\"listed_time\", LongType(), True),\n",
    "    StructField(\"posting_domain\", StringType(), True),\n",
    "    StructField(\"sponsored\", IntegerType(), True),\n",
    "    StructField(\"work_type\", StringType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "    StructField(\"compensation_type\", StringType(), True),\n",
    "    StructField(\"scraped\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd1b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posting = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .schema(job_postings_schema) \\\n",
    "    .csv(\"gs://de-zoomcamp-xiangivyli/final_project/raw/job_postings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d44bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/30 10:09:58 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+----------+----------+----------+----------+-------------------+----------------+-------+--------------------+--------------+-----+--------------------+--------------------+----------------+------+-----------+--------------------------+--------------------+-----------+--------------------+---------+---------+--------+-----------------+----------+\n",
      "|    job_id|company_id|               title|         description|max_salary|med_salary|min_salary|pay_period|formatted_work_type|        location|applies|original_listed_time|remote_allowed|views|     job_posting_url|     application_url|application_type|expiry|closed_time|formatted_experience_level|         skills_desc|listed_time|      posting_domain|sponsored|work_type|currency|compensation_type|   scraped|\n",
      "+----------+----------+--------------------+--------------------+----------+----------+----------+----------+-------------------+----------------+-------+--------------------+--------------+-----+--------------------+--------------------+----------------+------+-----------+--------------------------+--------------------+-----------+--------------------+---------+---------+--------+-----------------+----------+\n",
      "|3757940104|    553718|Hearing Care Prov...|Overview\\n\\nHeari...|      null|    5250.0|      null|   MONTHLY|          Full-time|Little River, SC|   null|                null|          null|    9|https://www.linke...|https://careers-d...|    OffsiteApply|  null|       null|               Entry level|                null|       null|careers-demant.ic...|        0|FULL_TIME|     USD|      BASE_SALARY|1699138101|\n",
      "|3757940025|   2192142|Shipping & Receiv...|Metalcraft of May...|      null|      null|      null|      null|          Full-time|  Beaver Dam, WI|   null|                null|          null| null|https://www.linke...|https://www.click...|    OffsiteApply|  null|       null|                      null|                null|       null| www.click2apply.net|        0|FULL_TIME|    null|             null|1699085420|\n",
      "|3757938019|    474443|Manager, Engineering|\\nThe TSUBAKI nam...|      null|      null|      null|      null|          Full-time|    Bessemer, AL|   null|                null|          null| null|https://www.linke...|https://www.click...|    OffsiteApply|  null|       null|                      null|Bachelor's Degree...|       null| www.click2apply.net|        0|FULL_TIME|    null|             null|1699085644|\n",
      "|3757938018|  18213359|                Cook|descriptionTitle\\...|      null|     22.27|      null|    HOURLY|          Full-time| Aliso Viejo, CA|   null|                null|          null|    1|https://www.linke...|https://jobs.appl...|    OffsiteApply|  null|       null|               Entry level|                null|       null|     jobs.apploi.com|        0|FULL_TIME|     USD|      BASE_SALARY|1699087461|\n",
      "|3757937095|    437225|Principal Cloud S...|Job Summary\\nAt i...|  275834.0|      null|  205956.0|    YEARLY|          Full-time|   United States|   null|                null|             1| null|https://www.linke...|https://careers.i...|    OffsiteApply|  null|       null|          Mid-Senior level|                null|       null|   careers.iherb.com|        0|FULL_TIME|     USD|      BASE_SALARY|1699085346|\n",
      "+----------+----------+--------------------+--------------------+----------+----------+----------+----------+-------------------+----------------+-------+--------------------+--------------+-----+--------------------+--------------------+----------------+------+-----------+--------------------------+--------------------+-----------+--------------------+---------+---------+--------+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_posting.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41840bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of your timestamp columns\n",
    "timestamp_columns = [\"original_listed_time\", \"expiry\", \"closed_time\", \"listed_time\"]\n",
    "\n",
    "# Convert from Unix time in milliseconds to a proper timestamp\n",
    "# Loop through the list and apply the transformation to each column\n",
    "for column_name in timestamp_columns:\n",
    "    df_posting = df_posting.withColumn(\n",
    "        column_name,\n",
    "        (col(column_name) / 1000).cast(\"timestamp\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28841348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_posting.repartition(10).write.parquet(\"gs://de-zoomcamp-xiangivyli/final_project/pq-linkedin-job-postings/job_posting_pq/\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
